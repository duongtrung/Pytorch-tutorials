{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dde4446-025b-424c-902c-6ff9bb41bb61",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/duongtrung/Pytorch-tutorials/blob/main/04_pytorch_custom_datasets_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ae0677-7a47-4701-9d56-54afdc314154",
   "metadata": {},
   "source": [
    "# 04. PyTorch Custom Datasets\n",
    "\n",
    "In the last notebook, [notebook 03](03_pytorch_computer_vision_up.ipynb/), we looked at how to build computer vision models on an in-built dataset in PyTorch (FashionMNIST).\n",
    "\n",
    "The steps we took are similar across many different problems in machine learning.\n",
    "\n",
    "Find a dataset, turn the dataset into numbers, build a model (or find an existing model) to find patterns in those numbers that can be used for prediction.\n",
    "\n",
    "PyTorch has many built-in datasets used for a wide number of machine learning benchmarks, however, you'll often want to use your own **custom dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e1dc4-d67a-4c51-b540-5f3f45d3cb0c",
   "metadata": {},
   "source": [
    "## What is a custom dataset?\n",
    "\n",
    "A **custom dataset** is a collection of data relating to a specific problem you're working on.\n",
    "\n",
    "In essence, a **custom dataset** can be comprised of almost anything.\n",
    "\n",
    "For example, if we were building a food image classification app like [Nutrify](https://nutrify.app), our custom dataset might be images of food.\n",
    "\n",
    "Or if we were trying to build a model to classify whether or not a text-based review on a website was positive or negative, our custom dataset might be examples of existing customer reviews and their ratings.\n",
    "\n",
    "Or if we were trying to build a sound classification app, our custom dataset might be sound samples alongside their sample labels.\n",
    "\n",
    "Or if we were trying to build a recommendation system for customers purchasing things on our website, our custom dataset might be examples of products other people have bought.\n",
    "\n",
    "<img src=\"resources/04-pytorch-domain-libraries.jpg\" alt=\"different pytorch domain libraries can be used for specific PyTorch problems\" width=1000/>\n",
    "\n",
    "*PyTorch includes many existing functions to load in various custom datasets in the [`TorchVision`](https://pytorch.org/vision/stable/index.html), [`TorchText`](https://pytorch.org/text/stable/index.html), [`TorchAudio`](https://pytorch.org/audio/stable/index.html) and [`TorchRec`](https://pytorch.org/torchrec/) domain libraries.*\n",
    "\n",
    "But sometimes these existing functions may not be enough.\n",
    "\n",
    "In that case, we can always subclass `torch.utils.data.Dataset` and customize it to our liking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e0a4a-5530-4d2c-84d9-b72fc28b3163",
   "metadata": {},
   "source": [
    "## What we're going to cover\n",
    "\n",
    "We're going to be applying the PyTorch Workflow we covered in [notebook 01](01_pytorch_workflow_up.ipynb) and [notebook 02](02_pytorch_classification_up.ipynb) to a computer vision problem.\n",
    "\n",
    "But instead of using an in-built PyTorch dataset, we're going to be using our own dataset of pizza, steak and sushi images.\n",
    "\n",
    "The goal will be to load these images and then build a model to train and predict on them.\n",
    "\n",
    "<img src=\"resources/04-pytorch-food-vision-layout.jpg\" alt=\"building a pipeline to load in food images and then building a pytorch model to classify those food images\" width=800 />\n",
    "\n",
    "*What we're going to build. We'll use `torchvision.datasets` as well as our own custom `Dataset` class to load in images of food and then we'll build a PyTorch computer vision model to hopefully be able to classify them.*\n",
    "\n",
    "Specifically, we're going to cover:\n",
    "\n",
    "| **Topic** | **Contents** |\n",
    "| ----- | ----- |\n",
    "| **0. Importing PyTorch and setting up device-agnostic code** | Let's get PyTorch loaded and then follow best practice to setup our code to be device-agnostic.  |\n",
    "| **1. Get data** | We're going to be using our own **custom dataset** of pizza, steak and sushi images. |\n",
    "| **2. Become one with the data (data preparation)** | At the beginning of any new machine learning problem, it's paramount to understand the data you're working with. Here we'll take some steps to figure out what data we have. |\n",
    "| **3. Transforming data** |Often, the data you get won't be 100% ready to use with a machine learning model, here we'll look at some steps we can take to *transform* our images so they're ready to be used with a model. | \n",
    "| **4. Loading data with `ImageFolder` (option 1)** | PyTorch has many in-built data loading functions for common types of data. `ImageFolder` is helpful if our images are in standard image classification format. |\n",
    "| **5. Loading image data with a custom `Dataset`** | What if PyTorch didn't have an in-built function to load data with? This is where we can build our own custom subclass of `torch.utils.data.Dataset`. |\n",
    "| **6. Other forms of transforms (data augmentation)** | Data augmentation is a common technique for expanding the diversity of your training data. Here we'll explore some of `torchvision`'s in-built data augmentation functions. |\n",
    "| **7. Model 0: TinyVGG without data augmentation** | By this stage, we'll have our data ready, let's build a model capable of fitting it. We'll also create some training and testing functions for training and evaluating our model. |\n",
    "| **8. Exploring loss curves** | Loss curves are a great way to see how your model is training/improving over time. They're also a good way to see if your model is **underfitting** or **overfitting**. |\n",
    "| **9. Model 1: TinyVGG with data augmentation** | By now, we've tried a model *without*, how about we try one *with* data augmentation? |\n",
    "| **10. Compare model results** | Let's compare our different models' loss curves and see which performed better and discuss some options for improving performance. |\n",
    "| **11. Making a prediction on a custom image** | Our model is trained to on a dataset of pizza, steak and sushi images. In this section we'll cover how to use our trained model to predict on an image *outside* of our existing dataset. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee836a-95dc-4dbe-9722-6de101f2d037",
   "metadata": {},
   "source": [
    "## 0. Importing PyTorch and setting up device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e174d829-af14-49b2-9024-05b5f58ff226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Note: this notebook requires torch >= 1.10.0\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8fb4b1-cb6b-45b0-bb1a-eb8c3aff8795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40724a2d-44ac-4b82-9e45-ced9ae509516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
