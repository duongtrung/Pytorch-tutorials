{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7ee10f-b0e6-4c13-9dd8-165b4f5ed71e",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/duongtrung/Pytorch-tutorials/blob/main/06_pytorch_transfer_learning_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4bd61-e32c-4663-bd90-f0f97d967b9c",
   "metadata": {},
   "source": [
    "# 06. PyTorch Transfer Learning\n",
    "\n",
    "> **Note:** This notebook uses `torchvision`'s new [multi-weight support API (available in `torchvision` v0.13+)](https://pytorch.org/blog/introducing-torchvision-new-multi-weight-support-api/).\n",
    "\n",
    "We've built a few models by hand so far, but you might be thinking, **is there a well-performing model that already exists for our problem?**\n",
    "\n",
    "And in the world of deep learning, the answer is often *yes*.\n",
    "\n",
    "We'll see how by using a powerful technique called [**transfer learning**](https://developers.google.com/machine-learning/glossary#transfer-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126b322-8dd7-4ad7-9177-702981ba9197",
   "metadata": {},
   "source": [
    "## What is transfer learning?\n",
    "\n",
    "**Transfer learning** allows us to take the patterns (also called weights) another model has learned from another problem and use them for our own problem.\n",
    "\n",
    "For example, we can take the patterns a computer vision model has learned from datasets such as [ImageNet](https://www.image-net.org/) (millions of images of different objects) and use them to power our FoodVision Mini model.\n",
    "\n",
    "Or we could take the patterns from a [language model](https://developers.google.com/machine-learning/glossary#masked-language-model) (a model that's been through large amounts of text to learn a representation of language) and use them as the basis of a model to classify different text samples.\n",
    "\n",
    "The premise remains: find a well-performing existing model and apply it to your own problem.\n",
    "\n",
    "<img src=\"resources/06-transfer-learning-example-overview.png\" alt=\"transfer learning overview on different problems\" width=600/>\n",
    "\n",
    "*Example of transfer learning being applied to computer vision and natural language processing (NLP). In the case of computer vision, a computer vision model might learn patterns on millions of images in ImageNet and then use those patterns to infer on another problem. And for NLP, a language model may learn the structure of language by reading all of Wikipedia (and perhaps more) and then apply that knowledge to a different problem.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5485eb44-9876-45ff-8f1b-085264e435be",
   "metadata": {},
   "source": [
    "## Why use transfer learning?\n",
    "\n",
    "There are two main benefits to using transfer learning:\n",
    "\n",
    "1. Can leverage an existing model (usually a neural network architecture) proven to work on problems similar to our own.\n",
    "2. Can leverage a working model which has **already learned** patterns on similar data to our own. This often results in achieving **great results with less custom data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab6ca8-ee23-4858-bff6-f26fe6c3ddb2",
   "metadata": {},
   "source": [
    "## Where to find pretrained models\n",
    "\n",
    "The world of deep learning is an amazing place.\n",
    "\n",
    "So amazing that many people around the world share their work.\n",
    "\n",
    "Often, code and pretrained models for the latest state-of-the-art research is released within a few days of publishing.\n",
    "\n",
    "And there are several places you can find pretrained models to use for your own problems.\n",
    "\n",
    "| **Location** | **What's there?** | **Link(s)** | \n",
    "| ----- | ----- | ----- |\n",
    "| **PyTorch domain libraries** | Each of the PyTorch domain libraries (`torchvision`, `torchtext`) come with pretrained models of some form. The models there work right within PyTorch. | [`torchvision.models`](https://pytorch.org/vision/stable/models.html), [`torchtext.models`](https://pytorch.org/text/main/models.html), [`torchaudio.models`](https://pytorch.org/audio/stable/models.html), [`torchrec.models`](https://pytorch.org/torchrec/torchrec.models.html) |\n",
    "| **HuggingFace Hub** | A series of pretrained models on many different domains (vision, text, audio and more) from organizations around the world. There's plenty of different datasets too. | https://huggingface.co/models, https://huggingface.co/datasets | \n",
    "| **`timm` (PyTorch Image Models) library** | Almost all of the latest and greatest computer vision models in PyTorch code as well as plenty of other helpful computer vision features. | https://github.com/rwightman/pytorch-image-models|\n",
    "| **Paperswithcode** | A collection of the latest state-of-the-art machine learning papers with code implementations attached. You can also find benchmarks here of model performance on different tasks. | https://paperswithcode.com/ | \n",
    "\n",
    "*With access to such high-quality resources as above, it should be common practice at the start of every deep learning problem you take on to ask, \"Does a pretrained model exist for my problem?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af4e7c-d616-4400-a5cc-1054666b3914",
   "metadata": {},
   "source": [
    "## What we're going to cover\n",
    "\n",
    "We're going to take a pretrained model from `torchvision.models` and customise it to work on (and hopefully improve) our FoodVision Mini problem.\n",
    "\n",
    "| **Topic** | **Contents** |\n",
    "| ----- | ----- |\n",
    "| **0. Getting setup** | We've written a fair bit of useful code over the past few sections, let's download it and make sure we can use it again. |\n",
    "| **1. Get data** | Let's get the pizza, steak and sushi image classification dataset we've been using to try and improve our model's results. |\n",
    "| **2. Create Datasets and DataLoaders** | We'll use the `data_setup.py` script we wrote in chapter 05. PyTorch Going Modular to setup our DataLoaders. |\n",
    "| **3. Get and customise a pretrained model** | Here we'll download a pretrained model from `torchvision.models` and customise it to our own problem. | \n",
    "| **4. Train model** | Let's see how the new pretrained model goes on our pizza, steak, sushi dataset. We'll use the training functions we created in the previous chapter. |\n",
    "| **5. Evaluate the model by plotting loss curves** | How did our first transfer learning model go? Did it overfit or underfit?  |\n",
    "| **6. Make predictions on images from the test set** | It's one thing to check out a model's evaluation metrics but it's another thing to view its predictions on test samples, let's *visualize, visualize, visualize*! |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58399ad-9ff2-4520-a032-5cc3c3e01571",
   "metadata": {},
   "source": [
    "## 0. Getting setup\n",
    "\n",
    "Let's get started by importing/downloading the required modules for this section.\n",
    "\n",
    "We'll also get the [`torchinfo`](https://github.com/TylerYep/torchinfo) package if it's not available. \n",
    "\n",
    "`torchinfo` will help later on to give us a visual representation of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d652862-1d2f-4155-8f64-69bb3c79bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.12.1\n",
      "torchvision version: 0.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f6962-3843-4d19-b69b-a36e0e0c64f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
