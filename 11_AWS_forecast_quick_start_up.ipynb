{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1ba26b-b3da-421f-8da3-51b2ea452b35",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/duongtrung/Pytorch-tutorials/blob/main/11_AWS_forecast_quick_start_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1166f-af5b-4a22-afec-0d0a3410d90a",
   "metadata": {},
   "source": [
    "## AWS forecast quick start\n",
    "\n",
    "AWS forecast involves the following 3 steps:\n",
    "\n",
    "<img src=\"resources/11-aws-quick-start-forecasting-overview.png\" width=900 alt=\"a aws forecast workflow\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e31627-c3ce-4397-8915-baa991064b6c",
   "metadata": {},
   "source": [
    "Imagine we are trying to solve the forecasting problem for a ride-hailing service and we want to predict how many pick-ups are expected in specific areas of New York. For this exercise, we will use the yellow taxi trip records from [NYC Taxi and Limousine Commission (TLC)](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
    "\n",
    "We will start by importing the historical data from December 2017 to January 2019, [link](https://raw.githubusercontent.com/aws-samples/amazon-forecast-samples/main/notebooks/basic/Getting_Started/data/taxi-dec2017-jan2019.csv). Next, we will train a Predictor using this data. Finally, we will generate a forecast for February 2019 and compare it with the actual data from February 2019, [link](https://raw.githubusercontent.com/aws-samples/amazon-forecast-samples/main/notebooks/basic/Getting_Started/data/taxi-feb2019.csv).\n",
    "\n",
    "You need to download the experimental datasets and put them in your data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792ff67-ea6f-4c0c-a693-a7b5e2c4b705",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "Before we get started, lets set up the notebook environment, the AWS SDK client for Amazon Forecast and IAM Role used by Amazon Forecast to access your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48766a5-ae36-4442-9354-b1328ab70c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following installation commmands are used for anaconda windows 11 64bit\n",
    "# I recommend to create conda env for your experiments\n",
    "# If you use other OS or docker, google how to prepare your machine.\n",
    "\n",
    "# conda install -c conda-forge s3fs\n",
    "# conda install -c anaconda ipywidgets\n",
    "# conda install -c anaconda boto3\n",
    "\n",
    "# https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\n",
    "# https://docs.aws.amazon.com/cli/latest/userguide/getting-started-prereqs.html\n",
    "\n",
    "# aws --version\n",
    "# aws-cli/2.7.33 Python/3.9.11 Windows/10 exe/AMD64 prompt/off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d41c2b-7e87-4e6b-9b97-1807e823003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert( 0, os.path.abspath(\"common-aws-forecast\") )\n",
    "\n",
    "import json\n",
    "import util\n",
    "import boto3\n",
    "import s3fs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffcfcd-ca6a-44ee-8d06-dd1434650301",
   "metadata": {},
   "source": [
    "### Create an instance of AWS SDK client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404036f9-2838-4871-a997-e55d4d397009",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'eu-central-1' # Europe (Frankfurt)\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast')\n",
    "forecastquery = session.client(service_name='forecastquery')\n",
    "\n",
    "# Checking to make sure we can communicate with Amazon Forecast\n",
    "assert forecast.list_predictors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d442e117-b6c7-41e2-8806-b3a58698d20e",
   "metadata": {},
   "source": [
    "### Setup IAM Role used by Amazon Forecast to access your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b50ae5f-29c8-44fe-8d90-65ff7fe07491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Role ForecastNotebookRole-Basic...\n",
      "The role ForecastNotebookRole-Basic already exists, skipping creation\n",
      "Done.\n",
      "Success! Created role = ForecastNotebookRole-Basic\n"
     ]
    }
   ],
   "source": [
    "role_name = \"ForecastNotebookRole-Basic\"\n",
    "print(f\"Creating Role {role_name}...\")\n",
    "role_arn = util.get_or_create_iam_role( role_name = role_name )\n",
    "\n",
    "# echo user inputs without account\n",
    "print(f\"Success! Created role = {role_arn.split('/')[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576b588-bc59-4f08-93f4-c5b59b4e759d",
   "metadata": {},
   "source": [
    "## Step 1: Import your data.\n",
    "\n",
    "In this step, we will create a Dataset and Import the December 2017 to January 2019 dataset from S3 to Amazon Forecast. To train a Predictor we will need a DatasetGroup that groups the input Datasets. So, we will end this step by creating a DatasetGroup with the imported Dataset.\n",
    "\n",
    "Peek at the data and upload it to S3.\n",
    "\n",
    "The taxi dataset has the following 3 columns:\n",
    "\n",
    "1. **timestamp**: Timetamp at which pick-ups are requested.\n",
    "2. **item_id**: Pick-up location ID.\n",
    "3. **target_value**: Number of pick-ups requested around the timestamp at the pick-up location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30dc443-68aa-4cfa-b75e-0af3698b13f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01 00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-01 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-01 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01 00:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01 00:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp item_id target_value\n",
       "0  2017-12-01 00:00:00       4           27\n",
       "1  2017-12-01 00:00:00       7           36\n",
       "2  2017-12-01 00:00:00      10            2\n",
       "3  2017-12-01 00:00:00      12            1\n",
       "4  2017-12-01 00:00:00      13           61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key=\"D:/gdrive/aws-taxi/taxi-dec2017-jan2019.csv\"   # replace with your path\n",
    "\n",
    "taxi_df = pd.read_csv(key, dtype = object, names=['timestamp','item_id','target_value']) # note that the column names are not in the data file\n",
    "display(taxi_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89f3c6d-15c5-4f37-8d01-a2764e28616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter S3 bucket name for uploading the data and hit ENTER key: aws-nghia-taxi-forecast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to upload the data to the S3 bucket 'aws-nghia-taxi-forecast' at key 'D:/gdrive/aws-taxi/taxi-dec2017-jan2019.csv' ...\n",
      "\n",
      "Done, the dataset is uploaded to S3 at s3://aws-nghia-taxi-forecast/D:/gdrive/aws-taxi/taxi-dec2017-jan2019.csv.\n"
     ]
    }
   ],
   "source": [
    "bucket_name = input(\"\\nEnter S3 bucket name for uploading the data and hit ENTER key:\")\n",
    "print(f\"\\nAttempting to upload the data to the S3 bucket '{bucket_name}' at key '{key}' ...\")\n",
    "\n",
    "s3 = boto3.Session().resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "if not bucket.creation_date:\n",
    "    if region != \"us-east-1\":\n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "s3.Bucket(bucket_name).Object(key).upload_file(key)\n",
    "ts_s3_path = f\"s3://{bucket_name}/{key}\"\n",
    "\n",
    "print(f\"\\nDone, the dataset is uploaded to S3 at {ts_s3_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa645e06-144e-496b-a566-32584ef55183",
   "metadata": {},
   "source": [
    "#### Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79cf293f-a36f-4b1d-b5f1-629017a228f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset with ARN arn:aws:forecast:eu-central-1:237468633482:dataset/TAXI_TS is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "DATASET_FREQUENCY = \"H\" # H for hourly.\n",
    "TS_DATASET_NAME = \"TAXI_TS\"\n",
    "TS_SCHEMA = {\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"integer\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "create_dataset_response = forecast.create_dataset(Domain=\"CUSTOM\",\n",
    "                                                  DatasetType='TARGET_TIME_SERIES',\n",
    "                                                  DatasetName=TS_DATASET_NAME,\n",
    "                                                  DataFrequency=DATASET_FREQUENCY,\n",
    "                                                  Schema=TS_SCHEMA)\n",
    "\n",
    "ts_dataset_arn = create_dataset_response['DatasetArn']\n",
    "describe_dataset_response = forecast.describe_dataset(DatasetArn=ts_dataset_arn)\n",
    "\n",
    "print(f\"The Dataset with ARN {ts_dataset_arn} is now {describe_dataset_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba744010-c4ba-428f-b655-dc4ea8a9a121",
   "metadata": {},
   "source": [
    "#### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7792e345-67fc-4212-961e-2b98cd67ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Dataset Import Job with ARN arn:aws:forecast:eu-central-1:237468633482:dataset-import-job/TAXI_TS/TAXI_TTS_IMPORT to become ACTIVE. This process could take 5-10 minutes.\n",
      "\n",
      "Current Status:\n",
      "CREATE_PENDING .\n",
      "CREATE_IN_PROGRESS ......................................................................................................................................\n",
      "ACTIVE \n",
      "\n",
      "\n",
      "The Dataset Import Job with ARN arn:aws:forecast:eu-central-1:237468633482:dataset-import-job/TAXI_TS/TAXI_TTS_IMPORT is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "TS_IMPORT_JOB_NAME = \"TAXI_TTS_IMPORT\"\n",
    "TIMEZONE = \"EST\"\n",
    "\n",
    "ts_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=TS_IMPORT_JOB_NAME,\n",
    "                                       DatasetArn=ts_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": ts_s3_path,\n",
    "                                             \"RoleArn\": role_arn\n",
    "                                         } \n",
    "                                       },\n",
    "                                       TimestampFormat=TIMESTAMP_FORMAT,\n",
    "                                       TimeZone = TIMEZONE)\n",
    "\n",
    "ts_dataset_import_job_arn = ts_dataset_import_job_response['DatasetImportJobArn']\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "\n",
    "print(f\"Waiting for Dataset Import Job with ARN {ts_dataset_import_job_arn} to become ACTIVE. This process could take 5-10 minutes.\\n\\nCurrent Status:\")\n",
    "\n",
    "status = util.wait(lambda: forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn))\n",
    "\n",
    "describe_dataset_import_job_response = forecast.describe_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn)\n",
    "print(f\"\\n\\nThe Dataset Import Job with ARN {ts_dataset_import_job_arn} is now {describe_dataset_import_job_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61fb6bf-2c8c-474e-96fc-c49f760c156b",
   "metadata": {},
   "source": [
    "#### Creating a DatasetGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447bdf65-ad06-424a-bfba-d7fa059c0fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
