{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d81a85-43b9-46ee-8b8a-f40813c0b4a7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/duongtrung/Pytorch-tutorials/blob/main/16_pytorch_weights_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada98c5-5395-4aee-aefb-e096505127fe",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to create, train, and extract weights from a neural network using PyTorch. We'll start by defining a dataset, building a more complex network, training it, and finally extracting its learned weights. Additionally, we will visualize the structure of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4af2c-c7a4-4ba9-8c25-c48900c54d6a",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "We begin by importing the necessary libraries: PyTorch for building and training the neural network, and NumPy for handling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44b4385-5367-49ab-9105-051e9916d2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dill' has no attribute 'extend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py:1442\u001b[0m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing \u001b[38;5;28;01mas\u001b[39;00m testing\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends \u001b[38;5;28;01mas\u001b[39;00m backends\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     BatchSampler,\n\u001b[0;32m      5\u001b[0m     RandomSampler,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     WeightedRandomSampler,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     ChainDataset,\n\u001b[0;32m     13\u001b[0m     ConcatDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     random_split,\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     DFIterDataPipe,\n\u001b[0;32m     23\u001b[0m     DataChunk,\n\u001b[0;32m     24\u001b[0m     IterDataPipe,\n\u001b[0;32m     25\u001b[0m     MapDataPipe,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     DataLoader,\n\u001b[0;32m     29\u001b[0m     _DatasetKind,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     default_convert,\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedSampler\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28miter\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mmap\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataframe\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     IterableWrapperIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m IterableWrapper,\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     CollatorIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Collator,\n\u001b[0;32m      6\u001b[0m     MapperIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Mapper,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinatorics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     SamplerIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Sampler,\n\u001b[0;32m     10\u001b[0m     ShufflerIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Shuffler,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\utils.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IterDataPipe\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterableWrapperIterDataPipe\u001b[39m\u001b[38;5;124m\"\u001b[39m, ]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIterableWrapperIterDataPipe\u001b[39;00m(IterDataPipe):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\datapipe.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _DataPipeMeta, _IterDataPipeMeta\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hook_iterator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SnapshotState\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatapipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     _deprecation_warning,\n\u001b[0;32m      9\u001b[0m     _iter_deprecated_functional_names,\n\u001b[0;32m     10\u001b[0m     _map_deprecated_functional_names,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, IterableDataset\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, Iterable, List, Optional, Tuple, Union\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DILL_AVAILABLE\n\u001b[0;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_input_col\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamWrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_pathname_binary_tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m ]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_input_col\u001b[39m(fn: Callable, input_col: Optional[Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m]]):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\serialization.py:8\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdill\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# XXX: By default, dill writes the Pickler dispatch table to inject its\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# own logic there. This globally affects the behavior of the standard library\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# pickler for any user who transitively depends on this module!\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Undo this extension to avoid altering the behavior of the pickler globally.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mdill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m(use_dill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m     DILL_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dill' has no attribute 'extend'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fef999-6ba8-4695-9f91-f6d99f6c41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Define the Dataset\n",
    "We define an example dataset using NumPy arrays and convert them to PyTorch tensors for training. This dataset contains some generalized data points to illustrate the process of training a neural network.\n",
    "\n",
    "```python\n",
    "# Example Dataset\n",
    "x = np.array([[0.1, 0.2], [0.3, 0.7], [0.5, 0.5], [0.8, 0.1], [0.9, 0.9]], dtype=np.float32)\n",
    "y = np.array([[0.2], [1.0], [0.5], [0.3], [0.9]], dtype=np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_tensor = torch.tensor(x)\n",
    "y_tensor = torch.tensor(y)\n",
    "```\n",
    "\n",
    "## Step 3: Define the Neural Network\n",
    "We define a neural network with two hidden layers: the first hidden layer containing three neurons and the second hidden layer containing two neurons. The `forward` method specifies how data passes through the network.\n",
    "\n",
    "```python\n",
    "# Define the neural network\n",
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.hidden1 = nn.Linear(2, 3)\n",
    "        self.hidden2 = nn.Linear(3, 2)\n",
    "        self.output = nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "## Step 4: Instantiate the Model, Define Loss Function, and Optimizer\n",
    "Next, we instantiate the model, define the loss function (`Mean Squared Error`), and choose the `Adam` optimizer to train the model.\n",
    "\n",
    "```python\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = ComplexNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "## Step 5: Train the Neural Network\n",
    "We train the network in a loop until it successfully learns the function. In each cycle, we perform a forward pass to compute predictions, calculate the loss, and then perform a backward pass to update the weights.\n",
    "\n",
    "```python\n",
    "# Training loop\n",
    "done = False\n",
    "cycle = 1\n",
    "while not done:\n",
    "    print(f\"Cycle #{cycle}\")\n",
    "    cycle += 1\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(x_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Check if successful\n",
    "    pred = outputs.detach().numpy()\n",
    "    done = np.allclose(pred, y, atol=0.1)\n",
    "    print(pred)\n",
    "```\n",
    "\n",
    "## Step 6: Extract the Weights\n",
    "After training, we can extract and print the weights and biases of each layer. This can help us understand what the network has learned.\n",
    "\n",
    "```python\n",
    "# Extracting weights\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.data}\")\n",
    "```\n",
    "\n",
    "## Step 7: Visualize the Neural Network Structure\n",
    "To better understand the structure of our neural network, we will visualize the connections between the input, hidden, and output layers.\n",
    "\n",
    "```python\n",
    "# Create a graph to visualize the neural network\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define the layers and nodes\n",
    "input_nodes = ['Input 1', 'Input 2']\n",
    "hidden_nodes_1 = ['Hidden 1-1', 'Hidden 1-2', 'Hidden 1-3']\n",
    "hidden_nodes_2 = ['Hidden 2-1', 'Hidden 2-2']\n",
    "output_nodes = ['Output']\n",
    "\n",
    "# Add nodes to the graph\n",
    "G.add_nodes_from(input_nodes + hidden_nodes_1 + hidden_nodes_2 + output_nodes)\n",
    "\n",
    "# Define edges with labels\n",
    "edges = [\n",
    "    ('Input 1', 'Hidden 1-1'), ('Input 1', 'Hidden 1-2'), ('Input 1', 'Hidden 1-3'),\n",
    "    ('Input 2', 'Hidden 1-1'), ('Input 2', 'Hidden 1-2'), ('Input 2', 'Hidden 1-3'),\n",
    "    ('Hidden 1-1', 'Hidden 2-1'), ('Hidden 1-1', 'Hidden 2-2'),\n",
    "    ('Hidden 1-2', 'Hidden 2-1'), ('Hidden 1-2', 'Hidden 2-2'),\n",
    "    ('Hidden 1-3', 'Hidden 2-1'), ('Hidden 1-3', 'Hidden 2-2'),\n",
    "    ('Hidden 2-1', 'Output'), ('Hidden 2-2', 'Output')\n",
    "]\n",
    "\n",
    "# Add edges to the graph\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Draw the network\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = {\n",
    "    'Input 1': (0, 1), 'Input 2': (0, 0),\n",
    "    'Hidden 1-1': (1, 2), 'Hidden 1-2': (1, 1), 'Hidden 1-3': (1, 0),\n",
    "    'Hidden 2-1': (2, 1.5), 'Hidden 2-2': (2, -0.5),\n",
    "    'Output': (3, 0.5)\n",
    "}\n",
    "\n",
    "# Draw nodes and edges with labels\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightgreen', font_size=10, font_weight='bold', arrows=True)\n",
    "plt.title('Visualization of Neural Network')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## Summary\n",
    "In this tutorial, we built a more complex neural network using PyTorch. We covered defining the dataset, building the model, training it, extracting the learned weights, and visualizing the structure of the neural network. This example provides a fundamental understanding of how neural networks work in PyTorch, which can be extended to more complex tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
