{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d81a85-43b9-46ee-8b8a-f40813c0b4a7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/duongtrung/Pytorch-tutorials/blob/main/16_pytorch_weights_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada98c5-5395-4aee-aefb-e096505127fe",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to create, train, and extract weights from a neural network using PyTorch. We'll start by defining a dataset, building a more complex network, training it, and finally extracting its learned weights. Additionally, we will visualize the structure of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4af2c-c7a4-4ba9-8c25-c48900c54d6a",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "We begin by importing the necessary libraries: PyTorch for building and training the neural network, and NumPy for handling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44b4385-5367-49ab-9105-051e9916d2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_functionalize_sync' from 'torch._utils' (C:\\Users\\Lena\\anaconda3\\lib\\site-packages\\torch\\_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py:28\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch._meta_registrations\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _import_dotted_name, classproperty\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_file_path, prepare_multiprocessing_environment, \\\n\u001b[1;32m---> 28\u001b[0m     USE_RTLD_GLOBAL_WITH_LIBTORCH, USE_GLOBAL_DEPS\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# TODO(torch_deploy) figure out how to freeze version.py in fbcode build\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _running_with_deploy():\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_functionalize_sync' from 'torch._utils' (C:\\Users\\Lena\\anaconda3\\lib\\site-packages\\torch\\_utils.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fef999-6ba8-4695-9f91-f6d99f6c41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Define the Dataset\n",
    "We define an example dataset using NumPy arrays and convert them to PyTorch tensors for training. This dataset contains some generalized data points to illustrate the process of training a neural network.\n",
    "\n",
    "```python\n",
    "# Example Dataset\n",
    "x = np.array([[0.1, 0.2], [0.3, 0.7], [0.5, 0.5], [0.8, 0.1], [0.9, 0.9]], dtype=np.float32)\n",
    "y = np.array([[0.2], [1.0], [0.5], [0.3], [0.9]], dtype=np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_tensor = torch.tensor(x)\n",
    "y_tensor = torch.tensor(y)\n",
    "```\n",
    "\n",
    "## Step 3: Define the Neural Network\n",
    "We define a neural network with two hidden layers: the first hidden layer containing three neurons and the second hidden layer containing two neurons. The `forward` method specifies how data passes through the network.\n",
    "\n",
    "```python\n",
    "# Define the neural network\n",
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.hidden1 = nn.Linear(2, 3)\n",
    "        self.hidden2 = nn.Linear(3, 2)\n",
    "        self.output = nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "## Step 4: Instantiate the Model, Define Loss Function, and Optimizer\n",
    "Next, we instantiate the model, define the loss function (`Mean Squared Error`), and choose the `Adam` optimizer to train the model.\n",
    "\n",
    "```python\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = ComplexNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "## Step 5: Train the Neural Network\n",
    "We train the network in a loop until it successfully learns the function. In each cycle, we perform a forward pass to compute predictions, calculate the loss, and then perform a backward pass to update the weights.\n",
    "\n",
    "```python\n",
    "# Training loop\n",
    "done = False\n",
    "cycle = 1\n",
    "while not done:\n",
    "    print(f\"Cycle #{cycle}\")\n",
    "    cycle += 1\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(x_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Check if successful\n",
    "    pred = outputs.detach().numpy()\n",
    "    done = np.allclose(pred, y, atol=0.1)\n",
    "    print(pred)\n",
    "```\n",
    "\n",
    "## Step 6: Extract the Weights\n",
    "After training, we can extract and print the weights and biases of each layer. This can help us understand what the network has learned.\n",
    "\n",
    "```python\n",
    "# Extracting weights\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.data}\")\n",
    "```\n",
    "\n",
    "## Step 7: Visualize the Neural Network Structure\n",
    "To better understand the structure of our neural network, we will visualize the connections between the input, hidden, and output layers.\n",
    "\n",
    "```python\n",
    "# Create a graph to visualize the neural network\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define the layers and nodes\n",
    "input_nodes = ['Input 1', 'Input 2']\n",
    "hidden_nodes_1 = ['Hidden 1-1', 'Hidden 1-2', 'Hidden 1-3']\n",
    "hidden_nodes_2 = ['Hidden 2-1', 'Hidden 2-2']\n",
    "output_nodes = ['Output']\n",
    "\n",
    "# Add nodes to the graph\n",
    "G.add_nodes_from(input_nodes + hidden_nodes_1 + hidden_nodes_2 + output_nodes)\n",
    "\n",
    "# Define edges with labels\n",
    "edges = [\n",
    "    ('Input 1', 'Hidden 1-1'), ('Input 1', 'Hidden 1-2'), ('Input 1', 'Hidden 1-3'),\n",
    "    ('Input 2', 'Hidden 1-1'), ('Input 2', 'Hidden 1-2'), ('Input 2', 'Hidden 1-3'),\n",
    "    ('Hidden 1-1', 'Hidden 2-1'), ('Hidden 1-1', 'Hidden 2-2'),\n",
    "    ('Hidden 1-2', 'Hidden 2-1'), ('Hidden 1-2', 'Hidden 2-2'),\n",
    "    ('Hidden 1-3', 'Hidden 2-1'), ('Hidden 1-3', 'Hidden 2-2'),\n",
    "    ('Hidden 2-1', 'Output'), ('Hidden 2-2', 'Output')\n",
    "]\n",
    "\n",
    "# Add edges to the graph\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Draw the network\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = {\n",
    "    'Input 1': (0, 1), 'Input 2': (0, 0),\n",
    "    'Hidden 1-1': (1, 2), 'Hidden 1-2': (1, 1), 'Hidden 1-3': (1, 0),\n",
    "    'Hidden 2-1': (2, 1.5), 'Hidden 2-2': (2, -0.5),\n",
    "    'Output': (3, 0.5)\n",
    "}\n",
    "\n",
    "# Draw nodes and edges with labels\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightgreen', font_size=10, font_weight='bold', arrows=True)\n",
    "plt.title('Visualization of Neural Network')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## Summary\n",
    "In this tutorial, we built a more complex neural network using PyTorch. We covered defining the dataset, building the model, training it, extracting the learned weights, and visualizing the structure of the neural network. This example provides a fundamental understanding of how neural networks work in PyTorch, which can be extended to more complex tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
